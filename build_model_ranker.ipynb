{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run boilerplate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=DataConversionWarning)\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.preprocessing import TargetEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold,train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ratings = pd.read_csv(DIR_DATA.joinpath('movies_ratings.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ratings = movies_ratings.fillna(movies_ratings.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(\"data/tags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_cols = {'Fantasy', 'Children', 'Animation', 'Comedy', 'Adventure', 'Romance',\n",
    "       'Drama', 'Action', 'Thriller', 'Crime', 'Horror', 'Mystery', 'Sci-Fi',\n",
    "       'War', 'Musical', 'Documentary', 'IMAX', 'Western'}\n",
    "catg_cols = {'primary_lang', 'cast_0', 'cast_1'}\n",
    "ord_cols = {'release_date_month', 'release_date_dow'}\n",
    "num_cols = { 'popularity','runtime', 'vote_average', 'vote_count', 'release_date_yr','years_from_release',\n",
    "        'rating'}\n",
    "\n",
    "feat_cols = genre_cols.union(num_cols).union(catg_cols).union(ord_cols)\n",
    "\n",
    "tgt = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersIds = movies_ratings.userId.unique()\n",
    "user_movie_watch = {u : movies_ratings.query(f'userId == {u}').movieId.unique() for u in usersIds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median and mode fill NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in feat_cols:\n",
    "    if movies_ratings[i].dtype in  {float, int}:\n",
    "        movies_ratings[i] = movies_ratings[i].fillna(movies_ratings[i].median())\n",
    "    else:\n",
    "        movies_ratings[i] = movies_ratings[i].fillna(movies_ratings[i].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie tag aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tags_ts_std = tags.groupby('movieId')[['timestamp']].std().add_suffix('_item_ts_std').fillna(0)\n",
    "movie_tags_ct = tags.groupby('movieId').size().to_frame(name = 'movi_tags_ct').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie items aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate movie features\n",
    "agg_movie_grps_df = pd.concat([\n",
    "        movies_ratings.groupby('movieId').rating.agg([np.min, np.max, np.mean, len, np.std]).add_prefix('item_rating_'),\n",
    "        movies_ratings.eval('yr_vote_diff = rating_yr - release_date_yr').groupby('movieId').yr_vote_diff.mean().to_frame().add_suffix('_item'),\n",
    "        movies_ratings.groupby('movieId').timestamp.std().to_frame().add_suffix('_item_std')\n",
    "], 1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging movie tags \n",
    "agg_movie_grps_tag_df = agg_movie_grps_df.merge(movie_tags_ct, on = 'movieId', how = 'left').merge(movie_tags_ts_std, on = 'movieId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_item_df = movies_ratings.drop(['userId', 'rating', 'tmdbId', 'imdbId','timestamp','rating_yr',],1)\n",
    "full_item_df = full_item_df.drop_duplicates().set_index('movieId')\n",
    "tmp = full_item_df.groupby('movieId').size()\n",
    "assert tmp.loc[lambda x :x>1].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing cast_1 and creating enc_cast_1 \n",
      "Removing primary_lang and creating enc_primary_lang \n",
      "Removing cast_0 and creating enc_cast_0 \n"
     ]
    }
   ],
   "source": [
    "# Fit target encoding\n",
    "lbl_enc = {}\n",
    "for cols in movies_ratings[feat_cols].select_dtypes(exclude=[float,int, bool]).columns:\n",
    "    feat_cols.remove(cols)\n",
    "    lbl_enc[cols] = TargetEncoder()\n",
    "    movies_ratings[f\"enc_{cols}\"] = lbl_enc[cols].fit_transform(movies_ratings[[cols]], movies_ratings[[tgt]])\n",
    "    num_cols.add(f\"enc_{cols}\")\n",
    "    feat_cols.add(f\"enc_{cols}\")\n",
    "    print(f\"Removing {cols} and creating enc_{cols} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cast_1\n",
      "primary_lang\n",
      "cast_0\n"
     ]
    }
   ],
   "source": [
    "# Perform Target encoding\n",
    "for col, enc in lbl_enc.items():\n",
    "    print(col)\n",
    "    full_item_df[f\"enc_{col}\"] = lbl_enc[col].transform(full_item_df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_item_df['rating_yr'] = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feat_cols difference with full_item\n",
    "assert len(feat_cols.difference(full_item_df.filter(feat_cols).columns).difference({tgt})) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create item df for inference evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_item_df = full_item_df.merge(agg_movie_grps_tag_df, on='movieId', how = 'left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = full_item_df.filter(feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating user attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_mean(x: pd.DataFrame):\n",
    "    \"\"\"Taking mean only when genre = 1\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for g in genre_cols:\n",
    "        mask = x[g]==1\n",
    "        res[g]  = x.loc[mask, tgt].mean()\n",
    "    return pd.Series(res)\n",
    "    \n",
    "def wt_avg(x, cols, tgt):\n",
    "    \"\"\"Apply wt avg for each cols based on tgt column\"\"\"\n",
    "    res = {}\n",
    "    for c in cols:\n",
    "        res[c] = np.average(x[c].values, weights=x[tgt].values)\n",
    "    return pd.Series(res)\n",
    "\n",
    "def genre_cum_norm(x):\n",
    "    \"\"\"Using timestamp apply Cumulative normalization by row for genere cols\"\"\"\n",
    "    x = x.set_index(['userId','timestamp']).groupby('timestamp').apply(lambda x: x[list(genre_cols)].mul(x['rating'], axis=0))\n",
    "    cumsum = (x.groupby('timestamp')[list(genre_cols)].sum()).cumsum()\n",
    "    return cumsum.div(cumsum.sum(axis=1), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_rating_diff(x, genre_rating):\n",
    "    \"\"\" Rating diff between user and global for each genre\"\"\"\n",
    "    genre_dist = x[list(genre_cols)].sum()\n",
    "    genre_dist = genre_dist/genre_dist.sum()\n",
    "    # display(genre_dist)\n",
    "    res = {}\n",
    "    for g,r in genre_rating.items():\n",
    "        mask = x[g]==1\n",
    "        if mask.any():\n",
    "            res[g] =  (x.loc[mask,'rating'].mean()) - r\n",
    "        else:\n",
    "            res[g] = 0\n",
    "    return pd.Series(res)\n",
    "        \n",
    "genre_rating = {g: movies_ratings.loc[movies_ratings[g] == 1, 'rating'].mean() for g in genre_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_watched_diff(x, genre_watched):\n",
    "    \"\"\"Compare Scaled movie watch vs Global movie watch by Genre\"\"\"\n",
    "    genre_dist = x[list(genre_cols)].sum()\n",
    "    genre_dist = genre_dist/genre_dist.sum()\n",
    "    return (genre_dist / genre_watched).apply(np.exp)\n",
    "    # # display(genre_dist)\n",
    "    # res = {}\n",
    "    # for g,r in genre_rating.items():\n",
    "    #     mask = x[g]==1\n",
    "    #     if mask.any():\n",
    "    #         res[g] =  (x.loc[mask,'rating'].mean()) - r\n",
    "    #     else:\n",
    "    #         res[g] = 0\n",
    "    # return pd.Series(res)\n",
    "        \n",
    "genre_watched = movies_ratings[list(genre_cols)].sum()/movies_ratings[list(genre_cols)].sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate user features\n",
    "def user_features(df):\n",
    "    usr_grp = df.groupby('userId')\n",
    "    usr_grp_genre_mean = usr_grp.apply(lambda x: genre_rating_diff(x, genre_rating)).add_suffix('_user_genre_rating_diff').fillna(0)\n",
    "    usr_grp_genre_dist = usr_grp.apply(genre_watched_diff, genre_watched).add_suffix('_user_genre_dist').fillna(0)\n",
    "\n",
    "    return pd.concat([\n",
    "        usr_grp_genre_mean,\n",
    "        usr_grp_genre_dist,\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_gen_feat = user_features(movies_ratings).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ts_genre_profile = movies_ratings.groupby('userId').apply(genre_cum_norm).add_suffix('_user_cum_norm').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Na columns\n",
    "assert (user_gen_feat.describe().T['count'] == user_gen_feat.shape[0]).all()\n",
    "assert (user_ts_genre_profile.userId.nunique() == user_gen_feat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = feat_cols.union(set(user_gen_feat.columns[1:])).union(set((user_ts_genre_profile.columns[2:])))\n",
    "num_cols = num_cols.union(set(user_gen_feat.columns[1:])).union(set((user_ts_genre_profile.columns[2:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User_gen_feat same number as unique userId\n",
    "assert movies_ratings.userId.nunique() == user_gen_feat.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge user info with movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = movies_ratings.merge(user_gen_feat, on='userId', validate=\"m:1\")\n",
    "assert tmp.shape[0] == movies_ratings.shape[0]\n",
    "movies_ratings = tmp.copy()\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = movies_ratings.merge(user_ts_genre_profile, on=['userId', 'timestamp'], validate=\"m:1\")\n",
    "assert tmp.shape[0] == movies_ratings.shape[0]\n",
    "movies_ratings = tmp.copy()\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_ts_genre_profile.columns[-1] not in user_gen_feat.columns:\n",
    "    last_user_ts_genre_profile = user_ts_genre_profile.groupby('userId').last().drop('timestamp',1)\n",
    "    user_gen_feat = user_gen_feat.merge(last_user_ts_genre_profile, on = 'userId', validate=\"1:1\")\n",
    "    user_gen_feat = user_gen_feat.set_index('userId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test data generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified Split by User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size =  90752 \n",
      "val_size =  10084 \n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = ut.split_train_val_test(movies_ratings[feat_cols.union({'userId', 'movieId'})], val_frac = 0.1, stratify=movies_ratings['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['has_rated'] = 1\n",
    "test_df['has_rated'] = 1\n",
    "# test_df = test_df.set_index('userId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_TRAIN_SAMPLES = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [19:46<00:00,  1.95s/it] \n"
     ]
    }
   ],
   "source": [
    "u_res = {}\n",
    "user_cols = list(user_gen_feat.columns)\n",
    "for u in tqdm(train_df.userId.unique()):\n",
    "    user_train_df = train_df[train_df.userId == u]\n",
    "    u_s = user_train_df.shape[0]\n",
    "    item_sample_df = full_item_df.loc[~full_item_df.index.isin(user_movie_watch[u])].sample(NEG_TRAIN_SAMPLES  * (u_s), replace=True).reset_index()\n",
    "    item_sample_df['rating'] = 0\n",
    "    res = []\n",
    "    for _, (i, user_row) in enumerate(user_train_df.iterrows()):\n",
    "        pos_df = user_row.to_frame().T.set_index('movieId')\n",
    "        neg_df = pos_df[user_cols].merge(item_sample_df.iloc[_ * NEG_TRAIN_SAMPLES: (_+1) *NEG_TRAIN_SAMPLES], how = 'cross').set_index('movieId')\n",
    "\n",
    "        res.append(neg_df[feat_cols].eval(\"has_rated = 0\"))\n",
    "        res.append(pos_df[feat_cols].eval(\"has_rated = 1\"))\n",
    "    u_res[u] = pd.concat(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_df = pd.concat(u_res, names=['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_df.reset_index().to_csv('data/train_rank_neg_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_TEST_SAMPLES = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/610 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [02:14<00:00,  4.53it/s]\n"
     ]
    }
   ],
   "source": [
    "u_res = {}\n",
    "user_cols = list(user_gen_feat.columns)\n",
    "for u in tqdm(test_df.userId.unique()):\n",
    "# for u in tqdm(train_neg_df.index.get_level_values(0).unique()):\n",
    "    user_train_df = test_df[test_df.userId == u]\n",
    "    u_s = user_train_df.shape[0]\n",
    "    movie_neg_test = full_item_df.index.difference(user_movie_watch[u]).difference(train_neg_df.loc[u].index)\n",
    "    item_sample_df = full_item_df.loc[movie_neg_test].sample(NEG_TEST_SAMPLES  * (u_s), replace=True).reset_index()\n",
    "    item_sample_df['rating'] = 0\n",
    "    res = []\n",
    "    \n",
    "    for _, (i, user_row) in enumerate(user_train_df.iterrows()):\n",
    "        pos_df = user_row.to_frame().T.set_index('movieId')\n",
    "        neg_df = pos_df[user_cols].merge(item_sample_df.iloc[_ * NEG_TEST_SAMPLES: (_+1) * NEG_TEST_SAMPLES], how = 'cross').set_index('movieId')\n",
    "\n",
    "        res.append(neg_df[feat_cols].eval(\"has_rated = 0\"))\n",
    "        res.append(pos_df[feat_cols].eval(\"has_rated = 1\"))\n",
    "    u_res[u] = pd.concat(res)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_df = pd.concat(u_res, names = ['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_df.reset_index().to_csv('data/test_rank_neg_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_df = pd.read_csv('data/train_rank_neg_df.csv')\n",
    "train_neg_df = train_neg_df.set_index(['userId', 'movieId']).drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_df = pd.read_csv('data/test_rank_neg_df.csv')\n",
    "test_neg_df = test_neg_df.set_index(['userId', 'movieId']).drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_wt =((train_neg_df['rating'].astype(int)*2 - 1) * train_neg_df['has_rated']) + 1\n",
    "test_sample_wt =(((test_neg_df['rating'].astype(int) - 1) * test_neg_df['has_rated']) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = feat_cols -{'rating', 'enc_primary_lang'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1815040, 85), (201680, 85))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg_df.shape, test_neg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815040, 94)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_neg_df.reset_index().merge(agg_movie_grps_tag_df, on='movieId')\n",
    " .set_index(['userId', 'movieId'])\n",
    ").fillna(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201680, 94)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_neg_df.reset_index().merge(agg_movie_grps_tag_df, on='movieId')\n",
    " .set_index(['userId', 'movieId'])\n",
    ").fillna(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging movie attributes in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_df =(train_neg_df.reset_index().reset_index().merge(agg_movie_grps_tag_df, on='movieId')\n",
    " .set_index(['index','userId', 'movieId'])\n",
    ").fillna(0).sort_index().reset_index('index', drop=True)\n",
    "\n",
    "test_neg_df = (test_neg_df.reset_index().reset_index().merge(agg_movie_grps_tag_df, on='movieId')\n",
    " .set_index(['index','userId', 'movieId'])\n",
    ").fillna(0).sort_index().reset_index('index', drop=True)\n",
    "feat_cols = feat_cols.union(agg_movie_grps_tag_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add query/sample index for each rated movie by user in train and test used for ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_queryid(x):\n",
    "    q = 0\n",
    "    prev_i = 0\n",
    "    res = []\n",
    "    for i in x:\n",
    "        q +=  prev_i \n",
    "        res.append(q)\n",
    "        prev_i = i\n",
    "    return pd.Series(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing added qid\n",
    "if 'qid' not in test_neg_df.index.names:\n",
    "    test_qids = test_neg_df.groupby('userId').has_rated.apply(add_queryid).reset_index(level=1, drop=True)\n",
    "    test_neg_df['qid'] = test_qids.values\n",
    "    test_neg_df.set_index('qid', append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training added qid\n",
    "if 'qid' not in train_neg_df.index.names:\n",
    "    test_qids = train_neg_df.groupby('userId').has_rated.apply(add_queryid).reset_index(level=1, drop=True)\n",
    "    train_neg_df['qid'] = test_qids.values\n",
    "    train_neg_df.set_index('qid', append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if has_rated is present in  20 samples (19 negative one positive)\n",
    "assert (test_neg_df.loc[1, 'has_rated'].head(20).iloc[-1] == 1)\n",
    "\n",
    "assert (train_neg_df.loc[1, 'has_rated'].head(20).iloc[-1] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle qid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test_neg_df.groupby(['userId', 'qid']).apply(lambda x: x.sample(frac=1)).reset_index(level=[0,1], drop=True)\n",
    "X_test, y_test = tmp[feat_cols], tmp[['has_rated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_neg_df.groupby(['userId', 'qid']).apply(lambda x: x.sample(frac=1)).reset_index(level=[0,1], drop=True)\n",
    "X_train, y_train = tmp[feat_cols], tmp[['has_rated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (test_neg_df.loc[1, 'has_rated'].head(20).sum() == 1)\n",
    "assert (train_neg_df.loc[1, 'has_rated'].head(20).sum() == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1815040, 91), (201680, 91))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.columns.symmetric_difference(X_test.columns).empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/610 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [13:37<00:00,  1.34s/it]  \n"
     ]
    }
   ],
   "source": [
    "user_models = {}\n",
    "i_train = 0\n",
    "i_test  = 0\n",
    "for u in tqdm(X_train.index.get_level_values(0).unique()):\n",
    "    qids_train = [20] * y_train.loc[u].sum().iloc[0]\n",
    "    qids_test = [20] * y_test.loc[u].sum().iloc[0]\n",
    "    \n",
    "    user_models[u] =  Pipeline(\n",
    "    [('p', \n",
    "                   Pipeline([\n",
    "                       ('poly', PolynomialFeatures(include_bias=False, interaction_only=True)),\n",
    "                       ('vif', VarianceThreshold()),\n",
    "                        ('ss', StandardScaler()),\n",
    "                        # ('f_select',  SelectPercentile(f_classif, percentile=25)),\n",
    "                       ])), \n",
    "                   ('reg', lgb.LGBMRanker(objective=\"lambdarank\",\n",
    "    metric=\"map\", n_jobs=-1, learning_rate=0.1,  n_estimators = 400, reg_lambda=0.2, verbose = -1, min_child_samples = 5, sub_feature=.65))\n",
    "    ])\n",
    "\n",
    "    user_models[u].fit(X_train.loc[u],\n",
    "        y_train.loc[u],\n",
    "        **{\n",
    "        \"reg__group\":qids_train,\n",
    "        \"reg__eval_set\":[(X_test.loc[u], y_test.loc[u])],\n",
    "        'reg__eval_metric': 'map',\n",
    "        \"reg__eval_group\":[qids_test],\n",
    "        \"reg__eval_at\":(3, 5),\n",
    "        \"reg__feature_name\":None,\n",
    "        # \"reg__sample_weight\": train_sample_wt[i:i + qid_len],\n",
    "        # \"reg__eval_sample_weight\": [test_sample_wt[i:i + qid_len]]*5,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding feat importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_feat_imp = {}\n",
    "for u,m in user_models.items():\n",
    "    res_feat_imp[u] = pd.Series(m.named_steps['reg'].feature_importances_, m.named_steps['p'].get_feature_names_out())\n",
    "res_feat_imp_agg = pd.concat(res_feat_imp).reset_index(name='feat_imp').groupby('level_1').feat_imp.mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Map 5 on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = []\n",
    "map_5 = []\n",
    "for u in user_models:\n",
    "    wts.append(movies_ratings.query(f'userId == {u}').shape[0])\n",
    "    map_5.append(pd.DataFrame(user_models[u].named_steps['reg'].evals_result_['valid_0'])['map@5'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5501038474809534"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(map_5, weights= wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T02:14:31.884655Z",
     "iopub.status.busy": "2023-12-30T02:14:31.884039Z",
     "iopub.status.idle": "2023-12-30T02:14:31.891368Z",
     "shell.execute_reply": "2023-12-30T02:14:31.890305Z",
     "shell.execute_reply.started": "2023-12-30T02:14:31.884613Z"
    }
   },
   "outputs": [],
   "source": [
    "train_feat = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on inference result by Hit Ratio @ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 610/610 [00:27<00:00, 21.80it/s]\n"
     ]
    }
   ],
   "source": [
    "rank_user_res = {}\n",
    "for u in tqdm(user_models):\n",
    "    pred = user_models[u].predict(X_test.loc[u])\n",
    "    udf = y_test.loc[u]\n",
    "    udf.loc[:,'pred'] = pred\n",
    "    udf.loc[:, 'rank'] = (udf.groupby('qid')['pred']\n",
    "                            .rank(method='dense', ascending=False).astype(int))\n",
    "\n",
    "    rank_user_res[u] = udf.query('has_rated == 1 and rank<=5').shape[0]/udf.query('has_rated == 1').shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375072489310825"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Hit ratio@5 for all user sample rated \n",
    "pd.Series(rank_user_res).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>has_rated</th>\n",
       "      <th>pred</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>79015</td>\n",
       "      <td>325</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>104.609335</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>79015</td>\n",
       "      <td>603</td>\n",
       "      <td>2829</td>\n",
       "      <td>0</td>\n",
       "      <td>104.331136</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>79015</td>\n",
       "      <td>448</td>\n",
       "      <td>149354</td>\n",
       "      <td>0</td>\n",
       "      <td>104.053013</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>79015</td>\n",
       "      <td>434</td>\n",
       "      <td>68954</td>\n",
       "      <td>0</td>\n",
       "      <td>104.940571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>79254</td>\n",
       "      <td>325</td>\n",
       "      <td>4086</td>\n",
       "      <td>1</td>\n",
       "      <td>104.265293</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>73226</td>\n",
       "      <td>558</td>\n",
       "      <td>367</td>\n",
       "      <td>0</td>\n",
       "      <td>105.429420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>73221</td>\n",
       "      <td>289</td>\n",
       "      <td>594</td>\n",
       "      <td>1</td>\n",
       "      <td>104.775600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>73221</td>\n",
       "      <td>610</td>\n",
       "      <td>111360</td>\n",
       "      <td>0</td>\n",
       "      <td>104.646484</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>73221</td>\n",
       "      <td>603</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>104.505416</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>73221</td>\n",
       "      <td>414</td>\n",
       "      <td>78574</td>\n",
       "      <td>0</td>\n",
       "      <td>104.540255</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40336 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                qid  userId  movieId  has_rated        pred  rank\n",
       "group_userId                                                     \n",
       "325           79015     325       58          1  104.609335     2\n",
       "325           79015     603     2829          0  104.331136     3\n",
       "325           79015     448   149354          0  104.053013     4\n",
       "325           79015     434    68954          0  104.940571     1\n",
       "325           79254     325     4086          1  104.265293     3\n",
       "...             ...     ...      ...        ...         ...   ...\n",
       "289           73226     558      367          0  105.429420     2\n",
       "289           73221     289      594          1  104.775600     1\n",
       "289           73221     610   111360          0  104.646484     2\n",
       "289           73221     603     1280          0  104.505416     4\n",
       "289           73221     414    78574          0  104.540255     3\n",
       "\n",
       "[40336 rows x 6 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_neg_df[['qid', 'userId', 'movieId', 'has_rated','pred','rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T23:02:23.251725Z",
     "iopub.status.busy": "2023-12-29T23:02:23.251101Z",
     "iopub.status.idle": "2023-12-29T23:02:23.258309Z",
     "shell.execute_reply": "2023-12-29T23:02:23.257009Z",
     "shell.execute_reply.started": "2023-12-29T23:02:23.251672Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib,pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./results/best_model/pipeline_rank_poly_V3.joblib']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(user_models, \"./results/best_model/pipeline_rank_poly_V3.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T23:02:23.836403Z",
     "iopub.status.busy": "2023-12-29T23:02:23.835956Z",
     "iopub.status.idle": "2023-12-29T23:02:23.844804Z",
     "shell.execute_reply": "2023-12-29T23:02:23.843603Z",
     "shell.execute_reply.started": "2023-12-29T23:02:23.836374Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./results/best_model/rank_train_feat.pkl', 'wb') as f:\n",
    "    pickle.dump(train_feat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
